{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/ubuntu/Mestrado/modelo_foguete/model/engines/decision_tree_model.pkl'\n",
    "path = '/home/ubuntu/Mestrado/modelo_foguete/improve_exec_speed/data/DecisionTreeRegressor_score_1.0.joblib'\n",
    "model = joblib.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/ubuntu/Mestrado/modelo_foguete/improve_exec_speed/data/grid_target.csv'\n",
    "df_grid_target = pd.read_csv(data_path)\n",
    "\n",
    "# Processa e converte para numpy\n",
    "X_y = df_grid_target.to_numpy()\n",
    "X = X_y[:,0:3]\n",
    "y = X_y[:,3:]\n",
    "\n",
    "# Deleta o dataframe para liberar espaco na RAM\n",
    "del df_grid_target\n",
    "\n",
    "# Divide os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56565657, 0.68686869, 0.53535354],\n",
       "       [0.38383838, 0.23232323, 0.11111111],\n",
       "       [0.24242424, 0.15151515, 0.19191919],\n",
       "       ...,\n",
       "       [0.13131313, 0.19191919, 0.32323232],\n",
       "       [0.67676768, 0.11111111, 0.55555556],\n",
       "       [0.12121212, 0.19191919, 0.58585859]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (200000,3) and (5,) not aligned: 3 (dim 1) != 5 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m X_test_with_intercept \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(X_test, has_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Fazendo previsões com o modelo sklearn para usar no OLS de statsmodels\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Ajustando o modelo OLS com os mesmos dados usados para previsões\u001b[39;00m\n\u001b[1;32m     11\u001b[0m ols_model \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mOLS(y_test, X_test_with_intercept)\u001b[38;5;241m.\u001b[39mfit()\n",
      "File \u001b[0;32m~/Installations/anaconda3/envs/deeplearning/lib/python3.10/site-packages/statsmodels/base/model.py:1176\u001b[0m, in \u001b[0;36mResults.predict\u001b[0;34m(self, exog, transform, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;124;03mCall self.model.predict with self.params as the first argument.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;124;03mreturned prediction.\u001b[39;00m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m exog, exog_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_predict_exog(exog,\n\u001b[1;32m   1174\u001b[0m                                                 transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m-> 1176\u001b[0m predict_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exog_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(predict_results,\n\u001b[1;32m   1180\u001b[0m                                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_values\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m predict_results\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Installations/anaconda3/envs/deeplearning/lib/python3.10/site-packages/statsmodels/regression/linear_model.py:411\u001b[0m, in \u001b[0;36mRegressionModel.predict\u001b[0;34m(self, params, exog)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    409\u001b[0m     exog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (200000,3) and (5,) not aligned: 3 (dim 1) != 5 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Adicionando uma coluna de uns para intercepto aos dados de teste\n",
    "X_test_with_intercept = sm.add_constant(X_test, has_constant='add')\n",
    "\n",
    "# Fazendo previsões com o modelo sklearn para usar no OLS de statsmodels\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Ajustando o modelo OLS com os mesmos dados usados para previsões\n",
    "ols_model = sm.OLS(y_test, X_test_with_intercept).fit()\n",
    "\n",
    "# Obtendo o sumário do modelo, que inclui os p-values\n",
    "print(ols_model.summary())\n",
    "\n",
    "# Se você quiser apenas os p-values, sem o sumário completo\n",
    "p_values = ols_model.pvalues\n",
    "print(p_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo para a dimensão 1\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.376\n",
      "Model:                            OLS   Adj. R-squared:                  0.376\n",
      "Method:                 Least Squares   F-statistic:                 4.024e+04\n",
      "Date:                Sat, 24 Feb 2024   Prob (F-statistic):               0.00\n",
      "Time:                        02:37:24   Log-Likelihood:            -1.0021e+06\n",
      "No. Observations:              200000   AIC:                         2.004e+06\n",
      "Df Residuals:                  199996   BIC:                         2.004e+06\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        210.5404      0.254    828.743      0.000     210.042     211.038\n",
      "x1            80.2527      0.278    288.313      0.000      79.707      80.798\n",
      "x2            23.1712      0.278     83.305      0.000      22.626      23.716\n",
      "x3           -48.8552      0.279   -175.242      0.000     -49.402     -48.309\n",
      "==============================================================================\n",
      "Omnibus:                    19400.439   Durbin-Watson:                   2.007\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            27179.179\n",
      "Skew:                          -0.779   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.913   Cond. No.                         6.12\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Modelo para a dimensão 2\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.278\n",
      "Model:                            OLS   Adj. R-squared:                  0.278\n",
      "Method:                 Least Squares   F-statistic:                 2.562e+04\n",
      "Date:                Sat, 24 Feb 2024   Prob (F-statistic):               0.00\n",
      "Time:                        02:37:24   Log-Likelihood:            -9.7615e+05\n",
      "No. Observations:              200000   AIC:                         1.952e+06\n",
      "Df Residuals:                  199996   BIC:                         1.952e+06\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        319.4928      0.223   1432.103      0.000     319.056     319.930\n",
      "x1           -11.0238      0.244    -45.099      0.000     -11.503     -10.545\n",
      "x2           -44.2743      0.244   -181.260      0.000     -44.753     -43.796\n",
      "x3            50.1132      0.245    204.695      0.000      49.633      50.593\n",
      "==============================================================================\n",
      "Omnibus:                    17767.950   Durbin-Watson:                   2.005\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            25451.266\n",
      "Skew:                          -0.714   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.007   Cond. No.                         6.12\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Modelo para a dimensão 3\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.112\n",
      "Model:                            OLS   Adj. R-squared:                  0.112\n",
      "Method:                 Least Squares   F-statistic:                     8412.\n",
      "Date:                Sat, 24 Feb 2024   Prob (F-statistic):               0.00\n",
      "Time:                        02:37:24   Log-Likelihood:            -1.3316e+06\n",
      "No. Observations:              200000   AIC:                         2.663e+06\n",
      "Df Residuals:                  199996   BIC:                         2.663e+06\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1450.2590      1.319   1099.514      0.000    1447.674    1452.844\n",
      "x1          -119.2984      1.445    -82.548      0.000    -122.131    -116.466\n",
      "x2           196.2520      1.444    135.896      0.000     193.422     199.082\n",
      "x3             0.9413      1.447      0.650      0.515      -1.896       3.778\n",
      "==============================================================================\n",
      "Omnibus:                     8682.805   Durbin-Watson:                   2.008\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7577.521\n",
      "Skew:                          -0.412   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.518   Cond. No.                         6.12\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Modelo para a dimensão 4\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.609\n",
      "Model:                            OLS   Adj. R-squared:                  0.609\n",
      "Method:                 Least Squares   F-statistic:                 1.039e+05\n",
      "Date:                Sat, 24 Feb 2024   Prob (F-statistic):               0.00\n",
      "Time:                        02:37:25   Log-Likelihood:            -7.1579e+05\n",
      "No. Observations:              200000   AIC:                         1.432e+06\n",
      "Df Residuals:                  199996   BIC:                         1.432e+06\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         54.8274      0.061    903.390      0.000      54.708      54.946\n",
      "x1             8.2972      0.066    124.775      0.000       8.167       8.428\n",
      "x2           -36.1688      0.066   -544.312      0.000     -36.299     -36.039\n",
      "x3            -0.0553      0.067     -0.831      0.406      -0.186       0.075\n",
      "==============================================================================\n",
      "Omnibus:                    22718.542   Durbin-Watson:                   2.006\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            31407.427\n",
      "Skew:                           0.917   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.634   Cond. No.                         6.12\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Modelo para a dimensão 5\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.168\n",
      "Model:                            OLS   Adj. R-squared:                  0.168\n",
      "Method:                 Least Squares   F-statistic:                 1.346e+04\n",
      "Date:                Sat, 24 Feb 2024   Prob (F-statistic):               0.00\n",
      "Time:                        02:37:25   Log-Likelihood:            -1.5260e+06\n",
      "No. Observations:              200000   AIC:                         3.052e+06\n",
      "Df Residuals:                  199996   BIC:                         3.052e+06\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       4282.2739      3.487   1228.235      0.000    4275.440    4289.107\n",
      "x1          -185.5534      3.820    -48.573      0.000    -193.041    -178.066\n",
      "x2          -744.0033      3.817   -194.903      0.000    -751.485    -736.522\n",
      "x3             2.0310      3.826      0.531      0.596      -5.468       9.530\n",
      "==============================================================================\n",
      "Omnibus:                    15107.156   Durbin-Watson:                   2.007\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18927.177\n",
      "Skew:                          -0.710   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.505   Cond. No.                         6.12\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Modelo para a dimensão 6\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.910\n",
      "Model:                            OLS   Adj. R-squared:                  0.910\n",
      "Method:                 Least Squares   F-statistic:                 6.700e+05\n",
      "Date:                Sat, 24 Feb 2024   Prob (F-statistic):               0.00\n",
      "Time:                        02:37:25   Log-Likelihood:             4.4461e+05\n",
      "No. Observations:              200000   AIC:                        -8.892e+05\n",
      "Df Residuals:                  199996   BIC:                        -8.892e+05\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.8826      0.000   4813.310      0.000       0.882       0.883\n",
      "x1            -0.0443      0.000   -220.582      0.000      -0.045      -0.044\n",
      "x2             0.2813      0.000   1400.917      0.000       0.281       0.282\n",
      "x3            -0.0002      0.000     -1.083      0.279      -0.001       0.000\n",
      "==============================================================================\n",
      "Omnibus:                     1078.617   Durbin-Watson:                   2.001\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1095.908\n",
      "Skew:                           0.181   Prob(JB):                    1.06e-238\n",
      "Kurtosis:                       2.978   Cond. No.                         6.12\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Supondo que X_test seja seus dados de teste e y_test seja um array com 6 dimensões\n",
    "# Cada coluna de y_test representa uma variável dependente diferente\n",
    "\n",
    "p_values_all = []  # Para armazenar os p-values de cada modelo\n",
    "\n",
    "for i in range(y_test.shape[1]):  # Assumindo que y_test é um DataFrame ou numpy array com 6 colunas\n",
    "    # Seleciona a i-ésima coluna de y_test como a variável dependente\n",
    "    y = y_test[:, i]\n",
    "    \n",
    "    # Adiciona um intercepto à matriz X_test\n",
    "    X_with_intercept = sm.add_constant(X_test)\n",
    "    \n",
    "    # Ajusta o modelo OLS para a i-ésima variável dependente\n",
    "    model = sm.OLS(y, X_with_intercept).fit()\n",
    "    \n",
    "    # Armazena os p-values deste modelo\n",
    "    p_values = model.pvalues\n",
    "    p_values_all.append(p_values)\n",
    "    \n",
    "    # Opcional: Imprimir o sumário para este modelo específico\n",
    "    print(f\"Modelo para a dimensão {i+1}\")\n",
    "    print(model.summary())\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# p_values_all agora contém os p-values para cada modelo ajustado a cada variável dependente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (200000,3) and (4,) not aligned: 3 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Printa o R-squared para cada uma das variáveis do modelo usando sklearn\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[0;32m----> 3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# for i in range(y_test.shape[1]):\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     y = y_test[:, i]\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     r2 = r2_score(y, predictions[i])\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     print(f\"R-squared para a dimensão {i+1}: {r2}\")\u001b[39;00m\n",
      "File \u001b[0;32m~/Installations/anaconda3/envs/deeplearning/lib/python3.10/site-packages/statsmodels/base/model.py:1176\u001b[0m, in \u001b[0;36mResults.predict\u001b[0;34m(self, exog, transform, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;124;03mCall self.model.predict with self.params as the first argument.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;124;03mreturned prediction.\u001b[39;00m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m exog, exog_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_predict_exog(exog,\n\u001b[1;32m   1174\u001b[0m                                                 transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m-> 1176\u001b[0m predict_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exog_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(predict_results,\n\u001b[1;32m   1180\u001b[0m                                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_values\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m predict_results\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Installations/anaconda3/envs/deeplearning/lib/python3.10/site-packages/statsmodels/regression/linear_model.py:411\u001b[0m, in \u001b[0;36mRegressionModel.predict\u001b[0;34m(self, params, exog)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    409\u001b[0m     exog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (200000,3) and (4,) not aligned: 3 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Printa o R-squared para cada uma das variáveis do modelo usando sklearn\n",
    "from sklearn.metrics import r2_score\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "# for i in range(y_test.shape[1]):\n",
    "#     y = y_test[:, i]\n",
    "#     r2 = r2_score(y, predictions[i])\n",
    "#     print(f\"R-squared para a dimensão {i+1}: {r2}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (200000,3) and (4,) not aligned: 3 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Installations/anaconda3/envs/deeplearning/lib/python3.10/site-packages/statsmodels/base/model.py:1176\u001b[0m, in \u001b[0;36mResults.predict\u001b[0;34m(self, exog, transform, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;124;03mCall self.model.predict with self.params as the first argument.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;124;03mreturned prediction.\u001b[39;00m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m exog, exog_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_predict_exog(exog,\n\u001b[1;32m   1174\u001b[0m                                                 transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m-> 1176\u001b[0m predict_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exog_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(predict_results,\n\u001b[1;32m   1180\u001b[0m                                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_values\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m predict_results\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Installations/anaconda3/envs/deeplearning/lib/python3.10/site-packages/statsmodels/regression/linear_model.py:411\u001b[0m, in \u001b[0;36mRegressionModel.predict\u001b[0;34m(self, params, exog)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    409\u001b[0m     exog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (200000,3) and (4,) not aligned: 3 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200000,), (200000,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:, i].shape, predictions[:,i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994155262395149"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=1\n",
    "r2_score(y_test[:, i], predictions[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula o p_score das predicoes\n",
    "\n",
    "p_values_all = []  # Para armazenar os p-values de cada modelo\n",
    "\n",
    "for i in range(y_test.shape[1]):  # Assumindo que y_test é um DataFrame ou numpy array com 6 colunas\n",
    "\n",
    "    # Seleciona a i-ésima coluna de y_test como a variável dependente\n",
    "    y = y_test[:, i]\n",
    "\n",
    "    # Adiciona um intercepto à matriz X_test\n",
    "    X_with_intercept = sm.add_constant(X_test)\n",
    "\n",
    "    # Ajusta o modelo OLS para a i-ésima variável dependente\n",
    "    model = sm.OLS(y, X_with_intercept).fit()\n",
    "\n",
    "    # Armazena os p-values deste modelo\n",
    "    p_values = model.pvalues\n",
    "    p_values_all.append(p_values)\n",
    "\n",
    "    # Opcional: Imprimir o sumário para este modelo específico\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0.]),\n",
       " array([0.        , 0.        , 0.        , 0.51547577]),\n",
       " array([0.      , 0.      , 0.      , 0.405947]),\n",
       " array([0.        , 0.        , 0.        , 0.59554129]),\n",
       " array([0.        , 0.        , 0.        , 0.27879546])]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([300.82271395, 275.82568994, 302.10897711, ..., 346.59421993,\n",
       "        354.75891483, 299.50593318]),\n",
       " array([300.44838695, 275.68348047, 302.48338718, ..., 344.95754775,\n",
       "        354.53832097, 299.30511875]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=1\n",
    "y_test[:, i], predictions[:,i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
